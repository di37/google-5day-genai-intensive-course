## Kaggle Generative AI Intensive Course - Day 1: Foundational Models & Prompt Engineering

**Agenda:**

0. **Introduction & Course Overview (0:00 - 2:27):** Introduction to the 5-day intensive course on Generative AI, daily assignments, resources, and the agenda for the first day.
1. **Q&A Session with Expert Panel (2:27 - 34:27):** Deep dive into recent advancements in foundational models, grounding with Google Search, open-source compatibility, multimodal applications, RLHF, and model evaluation.
2. **Code Labs & Demos (34:27 - 54:29):**  Practical walkthrough of code examples showcasing prompt engineering techniques, different model capabilities, and API interaction.
3. **Pop Quiz (54:29 - 62:44):** Knowledge check on core concepts from the white papers, podcast, and Q&A sessions.

**1. Introduction & Course Overview**

- The Kaggle Generative AI Intensive course is a 5-day virtual program delivered in collaboration with Google. 
- The course aims to provide comprehensive knowledge about Generative AI and its application in AI projects.
- Daily assignments will involve reading white papers and listening to podcasts.
- These resources explain the workings of generative AI models, tools like vector databases, and various techniques involved.
- Accompanying code labs demonstrate the practical use of generative AI APIs, open-source tools, and other relevant assets.
- A dedicated Discord channel is available for discussions, brainstorming, and Q&A with guest speakers.

**2. Q&A Session with Expert Panel**

**2.1. Recent Advancements in Foundational Models:**

- **Grounding with Google Search:**
    - This feature, recently launched in AI Studio, allows LLMs to access and utilize Google's vast search index for grounding answers.
    - It helps address issues like hallucination and improves the accuracy of responses by providing real-world information.
- **OpenAI Compatibility:**
    - Gemini models now offer compatibility with OpenAI SDKs and libraries.
    - Developers familiar with OpenAI can easily switch to Gemini models by making minimal code changes. 
    - This reduces friction and encourages broader adoption of Gemini. 

**2.2. Efficient Model Deployment:**

- **Gemini Flash Series (Flash API):**
    - Flash API represents the smallest hosted Gemini model, with 8 billion parameters.
    - It focuses on delivering high compute intelligence per dollar, with extremely low token costs.
    - Flash models address the cost barrier for developers, enabling them to implement AI solutions without significant cost concerns.

**2.3. Exploring Multimodal Applications:**

- **Potential of Multimodal Outputs:**
    - DeepMind's multimodal models, like Imagen and VÃ­o, open up exciting possibilities for generating diverse outputs beyond text.
    - While still early in development, these models have the potential to revolutionize how we interact with and consume information.
- **Example Use Cases:**
    - Book trailers automatically generated from PDFs.
    - Bringing text documents to life in audio or video form, for example, in the NotebookLM project.

**2.4.  Reinforcement Learning with Human Feedback (RLHF):**

- **Two-step Fine-tuning:**
    - State-of-the-art LLMs are fine-tuned in two stages: Supervised Fine-tuning (SFT) and RLHF.
    - SFT uses high-quality demonstration data, often generated by human experts, to train the model.
    - RLHF further aligns the model to human preferences, making responses safer, more helpful, and factually accurate.
- **Reward Model and User Feedback:**
    - RLHF utilizes a reward model trained on preference data, either from human raters or user interactions.
    - The reward model penalizes bad responses and rewards good ones, guiding the LLM towards generating more desirable outputs.
    - User feedback, such as thumbs-up/thumbs-down interactions, directly contributes to improving model performance over time.

**2.5. Beyond Training Data: LLMs Making New Discoveries:**

- **Beam Search and Model Capabilities:**
    - While LLMs learn from massive datasets, they are not limited to simple interpolation within that data.
    - Advanced techniques like Beam Search enable LLMs to explore the solution space beyond the training data, leading to new discoveries.
- **AlphaCode and Discovering New Solutions:**
    - AlphaCode, developed by DeepMind, demonstrates this capability by using an LLM to search for solutions to complex computer science and mathematics problems.
    - The LLM proposes solutions (code snippets), which are evaluated by an efficient evaluator. 
    - An evolutionary algorithm guides the LLM towards better solutions through an iterative process.
- **Test-Time Compute and Inference Scaling:**
    - Modern LLMs leverage techniques like test-time compute and inference scaling, where the model simulates different possibilities at inference time. 
    - By searching through these possibilities, LLMs can bootstrap their own knowledge and potentially discover novel solutions not present in the training data.

**2.6. Evaluating Large Language Models:**

- **Challenges in Evaluating LLMs:**
    - Evaluation depends on the specific task and the definition of "evaluation."
    - Classical natural language metrics like BLEU and ROUGE scores can be used when a golden ground truth is available. 
    - However, these metrics are not always suitable for complex tasks with diverse valid solutions.
- **LLM-Based Auto-Evaluators:**
    - Utilizing LLMs as auto-evaluators is a promising approach, where one LLM evaluates the response of another LLM.
    - This can be done in a pointwise (scoring a single response) or pairwise (comparing two responses) fashion.
- **Available Tools and Resources:**
    - Vertex AI's Generative AI evaluation service offers both LLM-based auto-evaluation and traditional metrics.
    - Open-source libraries like Promptfoo also provide tools for auto-rating and evaluation.

**3. Code Labs & Demos**

- **Setting Up for Code Labs:**
    - Phone verification is required for internet access. 
    - Users need to add their Kaggle secrets and Gemini API keys. 
    - The Generative AI SDK from AI Studio needs to be installed.
- **Single-Turn Prompting:**
    - A basic demonstration of sending a prompt to the Gemini API and receiving a response.
    - Example: "Explain AI to me like I'm a kid."
- **Conversational Interface:**
    - Showcases the ability to create a chat interface with Gemini, leveraging its memory and history features.
    - Demonstrates how Gemini remembers information from previous interactions within the same session. 
- **Listing and Inspecting Models:**
    - Provides methods for listing available models and retrieving detailed information about specific models (input token limit, output length, etc.).
- **Controlling Response Generation:**
    - **Output Length:** 
        - The `output_token_count` parameter limits the length of the response (number of tokens).
        - However, it does not force the LLM to provide meaningful responses within the specified limit, so careful prompt engineering is crucial.
    - **Temperature:** 
        - This parameter controls the randomness in token selection.
        - Lower temperature leads to more consistent outputs, while higher temperature encourages diversity and creativity.
        - Example: Generating different random colors with varying temperature values. 
    - **Top-K and Top-P:** 
        - These parameters limit the selection of tokens at each step to the top-k or top-p most likely candidates.
        - They can be used in conjunction with temperature to fine-tune the response generation.
- **Prompt Engineering Techniques:**
    - **Zero-Shot Prompting:** 
        - Providing a simple instruction and input without specific examples.
    - **Few-Shot Prompting:** 
        - Including one or multiple examples of input and output in the prompt to guide the LLM.
    - **Chain of Thought Prompting:** 
        - Encouraging the LLM to reason step-by-step, leading to more accurate answers for complex tasks. 
        - Example: Solving a word problem by eliciting intermediate reasoning steps.
    - **Reason and Act (ReAct):** 
        - Developed by Google, this framework enables multi-step workflows where the LLM can interleave thought, action, and observation steps.
        - This allows the LLM to utilize external tools, like APIs and SDKs, during the reasoning process.
- **Code Generation:**
    - Gemini models can be used for direct code generation.
    - They can also execute code by leveraging tools like the code execution tool within AI Studio.

**4. Pop Quiz**

1. **Which Gemini configuration setting controls the degree of randomness in the selection of the next predicted token?**
    - **Answer:** A) Temperature
2. **Which of the following is not a technique used to accelerate inference in large language models?**
    - **Answer:** D) Fine-tuning
3. **Which of the following is a unique characteristic of the Gemini family of large language models?**
    - **Answer:** D) Gemini models can support a context window of up to 2 million tokens.
4. **How does reinforcement learning from human feedback (RLHF) improve large language models?**
    - **Answer:** B) By using a reward model to incentivize the generation of human-preferred responses.
5. **Which technique enhances an LLM's reasoning abilities by prompting it to produce intermediate reasoning steps, leading to more accurate answers?**
    - **Answer:** D) Chain of thought prompting
6. **What is the minimum GPU memory needed for inference on a 3 billion parameter model using standard float precision?**
    - **Answer:** C) 12 Gigabytes

**5. Conclusion & Next Steps:**

- Day 1 focused on foundational models and prompt engineering techniques.
- The pop quiz tested knowledge on core concepts discussed during the Q&A and code labs.
- Day 2 will cover Vector Databases and Embeddings. 
