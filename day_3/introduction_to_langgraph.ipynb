{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: </b> I had to continue to use `ChatOpenAI` instead of `ChatGoogleGenerativeAI` as `bind_function` is not yet supported by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (0.2.48)\n",
      "Requirement already satisfied: langchain_openai in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (0.1.10)\n",
      "Requirement already satisfied: python-dotenv in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph) (0.2.43)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph) (2.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph) (0.1.36)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain_openai) (1.53.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.4.2)\n",
      "Requirement already satisfied: sniffio in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph langchain_openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Basic Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![basic example](screenshots/screenshot_one.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for each node\n",
    "def function_one(input_string):\n",
    "    return input_string + \" Hi \"\n",
    "\n",
    "def function_two(input_string):\n",
    "    return input_string + \"there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Graph object\n",
    "workflow = Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"node1\", function_one)\n",
    "workflow.add_node(\"node2\", function_two)\n",
    "\n",
    "# Add an edge between the nodes\n",
    "workflow.add_edge(\"node1\", \"node2\")\n",
    "\n",
    "# Set entry and exit points for the graph\n",
    "workflow.set_entry_point(\"node1\")\n",
    "workflow.set_finish_point(\"node2\")\n",
    "\n",
    "# Compile the graph app\n",
    "chain = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Hi there'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the output at Node level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node: node1: \n",
      "---\n",
      "Hello Hi \n",
      "\n",
      "---\n",
      "\n",
      "Output from node: node2: \n",
      "---\n",
      "Hello Hi there\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"Hello\"\n",
    "\n",
    "for output in chain.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node: {key}: \")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making use of LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![basic example](screenshots/screenshot_two.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-4244ccbb-4de4-4b69-a986-9e987279c631-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Set the model as ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "#Call the model with a user message\n",
    "model.invoke('Hey there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('Hey there').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "    response = model.invoke(input_1)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    return \"Agent Says: \" + input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Langchain graph\n",
    "workflow = Graph()\n",
    "\n",
    "#calling node 1 as agent\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "\n",
    "workflow.add_edge('agent', 'node_2')\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent Says: Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(\"Hey there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'node_2':\n",
      "---\n",
      "Agent Says: Hello! How can I assist you today?\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = 'Hey there'\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Functional Agent App - City Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![basic example](screenshots/screenshot_three.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Parse the city mentioned\n",
    "\n",
    "Let's extract the city that a user mentions in a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "    complete_query = \"Your task is to provide only the city name based on the user query. \\\n",
    "        Nothing more, just the city name mentioned. Following is the user query: \" + input_1\n",
    "    response = model.invoke(complete_query)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    return \"Agent Says: \" + input_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Langchain graph\n",
    "workflow = Graph()\n",
    "\n",
    "#calling node 1 as agent\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"node_2\", function_2)\n",
    "\n",
    "workflow.add_edge('agent', 'node_2')\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"node_2\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent Says: Dubai'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(\"What's the temperature in Dubai?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Adding a weather API call\n",
    "What if we want the function 2 to take the city name and give us the weather for that city.\n",
    "\n",
    "Well we know that Open Weather Map is integrated into LangChain\n",
    "\n",
    "We need to install pyown, create an API key on the website of Open Weather Map (which takes a few hours to activate) and then run the cells below to get weather of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyowm in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from pyowm) (2.32.3)\n",
      "Requirement already satisfied: geojson<3,>=2.3.0 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from pyowm) (2.5.0)\n",
      "Requirement already satisfied: PySocks<2,>=1.7.1 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from pyowm) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isham993/mambaforge/envs/bulla-fun/lib/python3.11/site-packages (from requests<3,>=2.20.0->pyowm) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import OpenWeatherMapAPIWrapper\n",
    "\n",
    "weather = OpenWeatherMapAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Dubai, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 2.57 m/s, direction: 180°\n",
      "Humidity: 78%\n",
      "Temperature: \n",
      "  - Current: 24.77°C\n",
      "  - High: 24.96°C\n",
      "  - Low: 22.16°C\n",
      "  - Feels like: 25.34°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 20%\n"
     ]
    }
   ],
   "source": [
    "weather_data = weather.run(\"Dubai\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's integrate this into function 2 and call the function two as a \"tool\" or \"weather_agent\" instead of \"node_2\" in our workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(input_1):\n",
    "    complete_query = \"Your task is to provide only the city name based on the user query. \\\n",
    "        Nothing more, just the city name mentioned. Following is the user query: \" + input_1\n",
    "    response = model.invoke(complete_query)\n",
    "    return response.content\n",
    "\n",
    "def function_2(input_2):\n",
    "    weather_data = weather.run(input_2)\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "#calling node 1 as agent\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "\n",
    "workflow.add_edge('agent', 'tool')\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"tool\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Dubai, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 2.57 m/s, direction: 180°\n",
      "Humidity: 78%\n",
      "Temperature: \n",
      "  - Current: 24.77°C\n",
      "  - High: 24.96°C\n",
      "  - Low: 22.16°C\n",
      "  - Feels like: 25.34°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 20%\n"
     ]
    }
   ],
   "source": [
    "print(app.invoke(\"What's the temperature in Dubai?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "Dubai\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tool':\n",
      "---\n",
      "In Dubai, the current weather is as follows:\n",
      "Detailed status: few clouds\n",
      "Wind speed: 2.57 m/s, direction: 180°\n",
      "Humidity: 78%\n",
      "Temperature: \n",
      "  - Current: 24.77°C\n",
      "  - High: 24.96°C\n",
      "  - Low: 22.16°C\n",
      "  - Feels like: 25.34°C\n",
      "Rain: {}\n",
      "Heat index: None\n",
      "Cloud cover: 20%\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"What's the temperature in Dubai?\"\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 Adding another LLM Call to filter results\n",
    "\n",
    "What if we only want the temperature? But current setup gives us the full weather report.\n",
    "\n",
    "Well we can make another LLM call to filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3(input_3):\n",
    "    complete_query = \"Your task is to provide info concisely based on the user query. Following is the user query: \" + \"user input\"\n",
    "    response = model.invoke(complete_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign AgentState as an empty dict\n",
    "AgentState = {}\n",
    "\n",
    "# messages key will be assigned as an empty array. We will append new messages as we pass along nodes. \n",
    "AgentState[\"messages\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AgentState\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to have this state filled as: {'messages': [HumanMessage, AIMessage, ...]]}\n",
    "\n",
    "Also now we need to modify our functions to pass info along the new AgentState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state):\n",
    "    messages = state['messages']\n",
    "    user_input = messages[-1]\n",
    "    complete_query = \"Your task is to provide only the city name based on the user query. \\\n",
    "                    Nothing more, just the city name mentioned. Following is the user query: \" + user_input\n",
    "    response = model.invoke(complete_query)\n",
    "    state['messages'].append(response.content) # appending AIMessage response to the AgentState\n",
    "    return state\n",
    "\n",
    "def function_2(state):\n",
    "    messages = state['messages']\n",
    "    agent_response = messages[-1]\n",
    "    weather = OpenWeatherMapAPIWrapper()\n",
    "    weather_data = weather.run(agent_response)\n",
    "    state['messages'].append(weather_data)\n",
    "    return state\n",
    "\n",
    "def function_3(state):\n",
    "    messages = state['messages']\n",
    "    user_input = messages[0]\n",
    "    available_info = messages[-1]\n",
    "    agent2_query = \"Your task is to provide info concisely based on the user query and the available information from the internet. \\\n",
    "                        Following is the user query: \" + user_input + \" Available information: \" + available_info\n",
    "    response = model.invoke(agent2_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import Graph\n",
    "\n",
    "workflow = Graph()\n",
    "\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "workflow.add_node(\"responder\", function_3)\n",
    "\n",
    "workflow.add_edge('agent', 'tool')\n",
    "workflow.add_edge('tool', 'responder')\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.set_finish_point(\"responder\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature in Dubai is 24.77°C, with a high of 24.96°C and a low of 22.16°C. It feels like 25.34°C.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"messages\": [\"what is the temperature in Dubai?\"]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': ['what is the temperature in Dubai?', 'Dubai']}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tool':\n",
      "---\n",
      "{'messages': ['what is the temperature in Dubai?', 'Dubai', 'In Dubai, the current weather is as follows:\\nDetailed status: few clouds\\nWind speed: 2.57 m/s, direction: 180°\\nHumidity: 78%\\nTemperature: \\n  - Current: 24.77°C\\n  - High: 24.96°C\\n  - Low: 22.16°C\\n  - Feels like: 25.34°C\\nRain: {}\\nHeat index: None\\nCloud cover: 20%']}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'responder':\n",
      "---\n",
      "The current temperature in Dubai is 24.77°C, with a high of 24.96°C and a low of 22.16°C. It feels like 25.34°C.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [\"what is the temperature in Dubai?\"]}\n",
    "for output in app.stream(input):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice that there is a lot of appending to the array going on, we can make it a bit easier with the following:\n",
    "```python\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "```\n",
    "\n",
    "```python\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "```\n",
    "\n",
    "It basically makes the state dictionary as saw previously, and also makes sure that any new message is appended to the messages array when we do the following:\n",
    "\n",
    "```python\n",
    "{\"messages\": [new_array_element]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also realize that our app is not capable of answering simple questions like \"how are you?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unable to find the resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m----> 2\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1844\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1844\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1573\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1571\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1573\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1580\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langgraph/pregel/runner.py:104\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    102\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, writer)\u001b[0m\n\u001b[1;32m     38\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langgraph/utils/runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[51], line 14\u001b[0m, in \u001b[0;36mfunction_2\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     12\u001b[0m agent_response \u001b[38;5;241m=\u001b[39m messages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m weather \u001b[38;5;241m=\u001b[39m OpenWeatherMapAPIWrapper()\n\u001b[0;32m---> 14\u001b[0m weather_data \u001b[38;5;241m=\u001b[39m \u001b[43mweather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(weather_data)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/langchain_community/utilities/openweathermap.py:73\u001b[0m, in \u001b[0;36mOpenWeatherMapAPIWrapper.run\u001b[0;34m(self, location)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the current weather information for a specified location.\"\"\"\u001b[39;00m\n\u001b[1;32m     72\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowm\u001b[38;5;241m.\u001b[39mweather_manager()\n\u001b[0;32m---> 73\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[43mmgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweather_at_place\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m w \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mweather\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_weather_info(location, w)\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/pyowm/weatherapi25/weather_manager.py:53\u001b[0m, in \u001b[0;36mWeatherManager.weather_at_place\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue must be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m: name}\n\u001b[0;32m---> 53\u001b[0m _, json_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOBSERVATION_URI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation\u001b[38;5;241m.\u001b[39mObservation\u001b[38;5;241m.\u001b[39mfrom_dict(json_data)\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/pyowm/commons/http_client.py:158\u001b[0m, in \u001b[0;36mHttpClient.get_json\u001b[0;34m(self, path, params, headers)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI call timeouted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m \u001b[43mHttpClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_status_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code, resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/mambaforge/envs/bulla-fun/lib/python3.11/site-packages/pyowm/commons/http_client.py:315\u001b[0m, in \u001b[0;36mHttpClient.check_status_code\u001b[0;34m(cls, status_code, payload)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnauthorizedError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid API Key provided\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to find the resource\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mBadGatewayError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to contact the upstream server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unable to find the resource"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [\"how are you?\"]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because we always want to parse a city and then find the weather.\n",
    "\n",
    "We can make our agent smarter by saying only use the tool when needed, if not just respond back to the user.\n",
    "\n",
    "The way we can do this LangGraph is:\n",
    "\n",
    "- binding a tool to the agent\n",
    "- adding a conditional edge to the agent with the option to either call the tool or not\n",
    "- defining the criteria for the conditional edge as when to call the tool. We will define a function for this.\n",
    "\n",
    "Let's start with the AgentState definition as mentioned a few cells above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![basic example](screenshots/screenshot_four.png){ width=100% }{ height=100% }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_community.tools.openweathermap import OpenWeatherMapQueryRun\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "tools = [OpenWeatherMapQueryRun()]\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, streaming=True)\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(state):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/t7k8b0897kv58vlclsc1_0xh0000gn/T/ipykernel_74705/3407288375.py:6: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  tool_executor = ToolExecutor(tools)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "def function_2(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] # this has the query we need to send to the tool provided by the agent\n",
    "\n",
    "    parsed_tool_input = json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"])\n",
    "\n",
    "    # We construct an ToolInvocation from the function_call and pass in the tool name and the expected str input for OpenWeatherMap tool\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=parsed_tool_input['location'],\n",
    "    )\n",
    "    \n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_to_go(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    if \"function_call\" in last_message.additional_kwargs:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.graph import Graph, END\n",
    "\n",
    "# workflow = Graph()\n",
    "\n",
    "# Or you could import StateGraph and pass AgentState to it\n",
    "from langgraph.graph import StateGraph, END\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", function_1)\n",
    "workflow.add_node(\"tool\", function_2)\n",
    "\n",
    "# The conditional edge requires the following info below.\n",
    "# First, we define the start node. We use `agent`.\n",
    "# This means these are the edges taken after the `agent` node is called.\n",
    "# Next, we pass in the function that will determine which node is called next, in our case where_to_go().\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", where_to_go,{   # Based on the return from where_to_go\n",
    "                                                        # If return is \"continue\" then we call the tool node.\n",
    "                                                        \"continue\": \"tool\",\n",
    "                                                        # Otherwise we finish. END is a special node marking that the graph should finish.\n",
    "                                                        \"end\": END\n",
    "                                                    }\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that if `tool` is called, then it has to call the 'agent' next. \n",
    "workflow.add_edge('tool', 'agent')\n",
    "\n",
    "# Basically, agent node has the option to call a tool node based on a condition, \n",
    "# whereas tool node must call the agent in all cases based on this setup.\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/t7k8b0897kv58vlclsc1_0xh0000gn/T/ipykernel_74705/3407288375.py:15: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the temperature in Dubai?'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"location\":\"Dubai\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-24ccd888-70d5-4dc2-bded-9f46ed9be553-0'),\n",
       "  FunctionMessage(content='In Dubai, the current weather is as follows:\\nDetailed status: few clouds\\nWind speed: 2.57 m/s, direction: 180°\\nHumidity: 78%\\nTemperature: \\n  - Current: 24.77°C\\n  - High: 24.96°C\\n  - Low: 22.16°C\\n  - Feels like: 25.34°C\\nRain: {}\\nHeat index: None\\nCloud cover: 20%', name='open_weather_map'),\n",
       "  AIMessage(content='The current temperature in Dubai is approximately 24.77°C, with a \"feels like\" temperature of 25.34°C. The weather is partly cloudy, with a humidity level of 78%.', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-c7e2a11e-e64c-4962-b6f2-c7c0b89456e7-0')]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What is the temperature in Dubai?\")]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"location\":\"Dubai\"}', 'name': 'open_weather_map'}}, response_metadata={'finish_reason': 'function_call', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1'}, id='run-7a3dd08e-588b-43be-a4f8-429356ba4e88-0')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/t7k8b0897kv58vlclsc1_0xh0000gn/T/ipykernel_74705/3407288375.py:15: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  action = ToolInvocation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'tool':\n",
      "---\n",
      "{'messages': [FunctionMessage(content='In Dubai, the current weather is as follows:\\nDetailed status: few clouds\\nWind speed: 2.57 m/s, direction: 180°\\nHumidity: 78%\\nTemperature: \\n  - Current: 24.77°C\\n  - High: 24.96°C\\n  - Low: 22.16°C\\n  - Feels like: 25.34°C\\nRain: {}\\nHeat index: None\\nCloud cover: 20%', name='open_weather_map')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current temperature in Dubai is approximately 24.77°C. It feels like 25.34°C, with a few clouds in the sky.', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f8dd36be86'}, id='run-57424ed0-a14c-4b8b-ba0f-b047a8f870c5-0')]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [HumanMessage(content=\"what is the temperature in dubai\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- YouTube Tutorial: https://www.youtube.com/watch?v=R8KB-Zcynxc&ab_channel=AIwithMisbah\n",
    "- GitHub: https://github.com/menloparklab/LangGraphJourney/blob/main/LangGraphLearning.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
